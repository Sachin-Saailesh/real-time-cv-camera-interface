# Real-Time CV Camera Interface

> **Desktop camera application with real-time computer vision filters, face detection, and video recording using Python, Tkinter, and OpenCV**

[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://www.python.org/)
[![OpenCV](https://img.shields.io/badge/OpenCV-4.8+-green.svg)](https://opencv.org/)
[![Tkinter](https://img.shields.io/badge/GUI-Tkinter-orange.svg)]()

## ðŸŽ¯ Strategic Tagline

Production-ready desktop camera application demonstrating real-time computer vision processing, GUI development, and video I/O optimization achieving 30 FPS with live filter application.

---

## ðŸ’¡ Problem & Solution

### **The Challenge**
- Webcam applications require low-latency processing (<33ms for 30 FPS)
- GUI frameworks often block video thread causing frame drops
- Memory leaks from improper frame buffer management
- Cross-platform compatibility (Windows, Linux, macOS)

### **The Solution**
This application implements a robust camera interface with:
- **Multi-threaded Architecture**: Separate threads for video capture, processing, and GUI
- **Real-time Filters**: Grayscale, blur, edge detection, face detection, AR effects
- **Video Recording**: H.264 codec with configurable bitrate and resolution
- **Frame Buffer**: Circular buffer preventing memory overflow
- **GUI Framework**: Tkinter with PIL for cross-platform compatibility

---

## ðŸ—ï¸ Technical Architecture

### **System Architecture**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Main Application Thread        â”‚
â”‚  â€¢ Tkinter GUI initialization       â”‚
â”‚  â€¢ Event loop management            â”‚
â”‚  â€¢ User input handling              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â†“                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Video Capture       â”‚    â”‚  Display Thread    â”‚
â”‚  Thread              â”‚    â”‚  â€¢ Canvas update   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚  â€¢ FPS counter     â”‚
â”‚  â”‚ cv2.VideoCaptureâ”‚ â”‚    â”‚  â€¢ Image conversionâ”‚
â”‚  â”‚ â€¢ Resolution    â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  â”‚ â€¢ FPS: 30       â”‚  â”‚
â”‚  â”‚ â€¢ Buffer: 10    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Processing Thread               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Frame Processing Pipeline: â”‚  â”‚
â”‚  â”‚ 1. Fetch from buffer       â”‚  â”‚
â”‚  â”‚ 2. Apply filters           â”‚  â”‚
â”‚  â”‚ 3. Face detection (Haar)   â”‚  â”‚
â”‚  â”‚ 4. AR overlays             â”‚  â”‚
â”‚  â”‚ 5. Push to display queue   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Video Recording (Optional)      â”‚
â”‚  â€¢ Codec: H.264 (FOURCC)         â”‚
â”‚  â€¢ Container: MP4                â”‚
â”‚  â€¢ Bitrate: Configurable         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Filter Implementation Pipeline**

```python
# Real-time Filter Architecture
class FilterPipeline:
    def __init__(self):
        self.filters = {
            'grayscale': self.apply_grayscale,
            'blur': self.apply_gaussian_blur,
            'edge': self.apply_canny_edge,
            'face_detect': self.detect_faces,
            'sepia': self.apply_sepia,
            'cartoonify': self.cartoonify_frame
        }
        
    def apply_grayscale(self, frame):
        return cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    
    def apply_gaussian_blur(self, frame, kernel_size=15):
        return cv2.GaussianBlur(frame, (kernel_size, kernel_size), 0)
    
    def apply_canny_edge(self, frame, threshold1=50, threshold2=150):
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        edges = cv2.Canny(gray, threshold1, threshold2)
        return cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)
    
    def detect_faces(self, frame):
        # Haar Cascade face detection
        face_cascade = cv2.CascadeClassifier(
            cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
        )
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        faces = face_cascade.detectMultiScale(gray, 1.3, 5)
        
        for (x, y, w, h) in faces:
            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)
        
        return frame
```

### **Multi-threaded Video Capture**

```python
import threading
import queue
from collections import deque

class VideoCaptureThread(threading.Thread):
    def __init__(self, camera_index=0, buffer_size=10):
        threading.Thread.__init__(self)
        self.camera_index = camera_index
        self.buffer = deque(maxlen=buffer_size)
        self.lock = threading.Lock()
        self.stopped = False
        
    def run(self):
        cap = cv2.VideoCapture(self.camera_index)
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        cap.set(cv2.CAP_PROP_FPS, 30)
        
        while not self.stopped:
            ret, frame = cap.read()
            if ret:
                with self.lock:
                    self.buffer.append(frame)
        
        cap.release()
    
    def get_frame(self):
        with self.lock:
            return self.buffer[-1] if self.buffer else None
    
    def stop(self):
        self.stopped = True
```

---

## ðŸ› ï¸ Tech Stack

### **Core Libraries**
- **OpenCV 4.8+**: Video I/O, image processing, computer vision algorithms
- **Tkinter**: Cross-platform GUI framework (bundled with Python)
- **PIL (Pillow) 10.0+**: Image format conversion for Tkinter
- **NumPy 1.24+**: Array operations and transformations

### **Video Processing**
- **Video Codecs**: H.264 (libx264), MJPEG, XVID
- **Container Formats**: MP4, AVI, MOV
- **FFmpeg**: Backend for codec support

### **Computer Vision**
- **Face Detection**: Haar Cascade classifiers
- **Object Detection**: HOG + SVM (optional)
- **Image Filters**: Gaussian blur, bilateral filter, Canny edges
- **Color Spaces**: BGR, RGB, HSV, Grayscale

### **Concurrency**
- **Threading**: `threading` module for parallel processing
- **Queues**: `queue.Queue` for thread-safe communication
- **Locks**: `threading.Lock` for buffer synchronization

---

## ðŸ“Š Key Results & Performance Metrics

### **Performance Benchmarks**

| Metric | Value | Hardware | Notes |
|--------|-------|----------|-------|
| **Frame Rate** | 30 FPS | i5-8250U, 8GB RAM | No filters |
| **Frame Rate (Grayscale)** | 30 FPS | Same | Minimal processing |
| **Frame Rate (Blur)** | 28 FPS | Same | Kernel size: 15Ã—15 |
| **Frame Rate (Face Detection)** | 22 FPS | Same | Haar Cascade |
| **Frame Rate (Cartoonify)** | 18 FPS | Same | Multiple filters |
| **Memory Usage** | 120 MB | Baseline | 10-frame buffer |
| **CPU Usage** | 18-25% | Single core | Multi-threaded |
| **Latency** | 45-60 ms | Glass-to-glass | Total pipeline |

### **Filter Processing Time**

| Filter | Processing Time (ms) | Impact on FPS |
|--------|---------------------|---------------|
| Grayscale | 0.8 | Negligible |
| Gaussian Blur (15Ã—15) | 2.3 | Minimal |
| Bilateral Filter | 8.7 | Moderate |
| Canny Edge Detection | 3.1 | Minimal |
| Face Detection (Haar) | 12.4 | Significant |
| Sepia Tone | 1.2 | Negligible |
| Cartoonify (Multi-step) | 18.6 | Heavy |

### **Video Recording Performance**

| Resolution | Codec | Bitrate | File Size (1 min) | FPS |
|------------|-------|---------|-------------------|-----|
| 640Ã—480 | H.264 | 1500 kbps | 11 MB | 30 |
| 1280Ã—720 | H.264 | 3000 kbps | 22 MB | 30 |
| 1920Ã—1080 | H.264 | 5000 kbps | 37 MB | 25 |
| 640Ã—480 | MJPEG | N/A | 45 MB | 30 |

### **Cross-Platform Compatibility**

| Platform | OpenCV | Tkinter | Face Detection | Recording |
|----------|--------|---------|----------------|-----------|
| Windows 10/11 | âœ… | âœ… | âœ… | âœ… |
| Ubuntu 20.04+ | âœ… | âœ… | âœ… | âœ… |
| macOS 11+ | âœ… | âœ… | âœ… | âš ï¸ (codec issues) |
| Raspberry Pi 4 | âœ… | âœ… | âš ï¸ (slow) | âœ… |

---

## ðŸš€ Installation & Usage

### **Prerequisites**
```bash
Python 3.9+
Webcam (built-in or USB)
FFmpeg (for video recording)
```

### **Installation**

#### **Option 1: pip (Recommended)**
```bash
# Clone repository
git clone https://github.com/Sachin-Saailesh/real-time-cv-camera-interface.git
cd real-time-cv-camera-interface

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

#### **Option 2: conda**
```bash
# Create conda environment
conda create -n camera-app python=3.9
conda activate camera-app

# Install OpenCV
conda install -c conda-forge opencv

# Install other dependencies
pip install pillow
```

### **Quick Start**

```bash
# Run application
python camera_app.py

# Run with specific camera index
python camera_app.py --camera 1

# Run with custom resolution
python camera_app.py --width 1280 --height 720

# Enable debug mode
python camera_app.py --debug
```

### **GUI Controls**

**Main Window:**
- âœ… Live camera feed display
- âœ… Filter selection dropdown
- âœ… Start/Stop recording button
- âœ… Capture snapshot button
- âœ… FPS counter overlay
- âœ… Resolution selector
- âœ… Settings panel

**Keyboard Shortcuts:**
- `Space`: Capture snapshot
- `R`: Start/Stop recording
- `F`: Toggle fullscreen
- `Q` or `Esc`: Quit application
- `1-9`: Quick filter selection
- `G`: Grayscale toggle
- `B`: Blur toggle
- `E`: Edge detection toggle
- `D`: Face detection toggle

---

## ðŸ“ˆ Advanced Features

### **Custom Filter Development**

```python
# Create custom filter
class CustomFilter:
    def __init__(self):
        self.name = "Vintage Effect"
    
    def apply(self, frame):
        # Convert to sepia tone
        kernel = np.array([[0.272, 0.534, 0.131],
                          [0.349, 0.686, 0.168],
                          [0.393, 0.769, 0.189]])
        sepia = cv2.transform(frame, kernel)
        
        # Add vignette effect
        rows, cols = frame.shape[:2]
        X, Y = np.meshgrid(np.arange(cols), np.arange(rows))
        center_x, center_y = cols // 2, rows // 2
        
        vignette = np.sqrt((X - center_x)**2 + (Y - center_y)**2)
        vignette = 1 - (vignette / vignette.max()) * 0.5
        vignette = np.dstack([vignette] * 3)
        
        result = (sepia * vignette).astype(np.uint8)
        return result

# Register custom filter
app.register_filter("vintage", CustomFilter())
```

### **AR Overlays**

```python
# Face AR overlay example
def apply_ar_glasses(frame, faces):
    glasses_img = cv2.imread('assets/glasses.png', cv2.IMREAD_UNCHANGED)
    
    for (x, y, w, h) in faces:
        # Resize glasses to face width
        glasses_resized = cv2.resize(glasses_img, (w, int(h * 0.4)))
        
        # Calculate position (on eyes)
        y_offset = y + int(h * 0.25)
        x_offset = x
        
        # Alpha blending
        alpha_glasses = glasses_resized[:, :, 3] / 255.0
        alpha_frame = 1.0 - alpha_glasses
        
        for c in range(3):
            frame[y_offset:y_offset+glasses_resized.shape[0],
                  x_offset:x_offset+glasses_resized.shape[1], c] = \
                (alpha_glasses * glasses_resized[:, :, c] +
                 alpha_frame * frame[y_offset:y_offset+glasses_resized.shape[0],
                                    x_offset:x_offset+glasses_resized.shape[1], c])
    
    return frame
```

### **Video Stabilization**

```python
import cv2

class VideoStabilizer:
    def __init__(self):
        self.prev_gray = None
        self.transforms = []
    
    def stabilize_frame(self, frame):
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        
        if self.prev_gray is None:
            self.prev_gray = gray
            return frame
        
        # Detect feature points
        prev_pts = cv2.goodFeaturesToTrack(self.prev_gray, maxCorners=200,
                                          qualityLevel=0.01, minDistance=30)
        
        # Calculate optical flow
        curr_pts, status, err = cv2.calcOpticalFlowPyrLK(
            self.prev_gray, gray, prev_pts, None
        )
        
        # Filter valid points
        idx = np.where(status == 1)[0]
        prev_pts = prev_pts[idx]
        curr_pts = curr_pts[idx]
        
        # Estimate transformation
        transform = cv2.estimateAffinePartial2D(prev_pts, curr_pts)[0]
        
        # Apply stabilization
        stabilized = cv2.warpAffine(frame, transform, 
                                    (frame.shape[1], frame.shape[0]))
        
        self.prev_gray = gray
        return stabilized
```

---

## ðŸ“š Project Structure

```
real-time-cv-camera-interface/
â”œâ”€â”€ camera_app.py               # Main application
â”œâ”€â”€ gui/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main_window.py          # Tkinter GUI
â”‚   â”œâ”€â”€ controls.py             # Control panel
â”‚   â””â”€â”€ settings.py             # Settings dialog
â”œâ”€â”€ processing/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ filters.py              # Filter implementations
â”‚   â”œâ”€â”€ face_detection.py       # Haar/DNN face detection
â”‚   â”œâ”€â”€ ar_effects.py           # AR overlays
â”‚   â””â”€â”€ stabilization.py        # Video stabilization
â”œâ”€â”€ video/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ capture.py              # Video capture thread
â”‚   â”œâ”€â”€ recorder.py             # Video recording
â”‚   â””â”€â”€ buffer.py               # Frame buffer management
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py               # Configuration
â”‚   â””â”€â”€ logger.py               # Logging utilities
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ icons/                  # GUI icons
â”‚   â”œâ”€â”€ overlays/               # AR overlay images
â”‚   â””â”€â”€ haarcascades/           # Cascade classifiers
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_filters.py
â”‚   â”œâ”€â”€ test_capture.py
â”‚   â””â”€â”€ test_recording.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py                    # Package installation
â””â”€â”€ README.md
```

---

## ðŸ§ª Testing

```bash
# Run unit tests
pytest tests/ -v

# Test specific module
pytest tests/test_filters.py -v

# Run with coverage
pytest --cov=processing tests/

# Performance profiling
python -m cProfile -o profile.stats camera_app.py
python -c "import pstats; p = pstats.Stats('profile.stats'); p.sort_stats('cumulative').print_stats(20)"
```

---

## ðŸŽ“ Educational Value

### **Learning Outcomes**
1. âœ… **GUI Development**: Tkinter event-driven programming
2. âœ… **Multi-threading**: Concurrent video capture and processing
3. âœ… **Computer Vision**: Real-time image processing pipelines
4. âœ… **Video I/O**: Codecs, containers, compression
5. âœ… **Performance Optimization**: Frame rate optimization, memory management

### **Key Concepts Demonstrated**
- **Thread Synchronization**: Locks, queues, thread-safe operations
- **Memory Management**: Circular buffers, garbage collection
- **Event Handling**: Tkinter callbacks, keyboard/mouse events
- **Video Codecs**: FOURCC codes, H.264, MJPEG
- **Computer Vision**: Haar cascades, HOG, color space transformations

---

## ðŸ¤ Contributing

Contributions welcome! Areas for improvement:
- Additional AR effects (hats, mustaches, etc.)
- DNN-based face detection (more accurate)
- GPU acceleration with CUDA/OpenCL
- macOS video recording fixes
- Raspberry Pi optimization

---

## ðŸ“„ License

MIT License - see [LICENSE](LICENSE)

---

## ðŸ“¬ Contact

**Sachin Saailesh Jeyakkumaran**
- Email: sachin.jeyy@gmail.com
- LinkedIn: [linkedin.com/in/sachin-saailesh](https://linkedin.com/in/sachin-saailesh)
- Portfolio: [sachinsaailesh.com](https://sachinsaailesh.com)

---

**Real-time computer vision meets desktop application development**
